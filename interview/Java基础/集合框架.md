### 常用的集合类有哪些？ 

Map接口和Collection接口是所有集合框架的父接口。下图中的实线和虚线看着有些乱，其中接口与接口之间如果有联系为继承关系，类与类之间如果有联系为继承关系，类与接口之间则是类实现接口。重点掌握的抽象类有**HashMap，LinkedList，HashTable，ArrayList，HashSet，Stack，TreeSet，TreeMap**。注意：Collection接口不是Map的父接口。 

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/71ad5b5d-1974-4a77-848b-3a96ff56d440_collection.jpg)

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/b115c8b4-9958-46a9-81b4-7ab486156cb3_map.jpg)



### List，Set，Map、Queuue的区别？ 

- List：有序集合（有序指存入的顺序和取出的顺序相同，不是按照元素的某些特性排序），可存储重复元素，可存储多个null。 
- Set：无序集合（元素存入和取出顺序不一定相同），不可存储重复元素，只能存储一个null。 
- Map：使用键值对的方式对元素进行存储，key是无序的，且是唯一的。value值不唯一。不同的key值可以对应相同的value值。
- Queue:  按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。



### 集合框架底层数据结构总结

先来看一下 `Collection` 接口下面的集合。

#### List

- `ArrayList`： `Object[]` 数组
- `Vector`：`Object[]` 数组
- `LinkedList`： 双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)

#### Set

- `HashSet`(无序，唯一): 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素
- `LinkedHashSet`: `LinkedHashSet` 是 `HashSet` 的子类，并且其内部是通过 `LinkedHashMap` 来实现的。有点类似于我们之前说的 `LinkedHashMap` 其内部是基于 `HashMap` 实现一样，不过还是有一点点区别的
- `TreeSet`(有序，唯一): 红黑树(自平衡的排序二叉树)

#### Queue

- `PriorityQueue`: `Object[]` 数组来实现二叉堆
- `ArrayQueue`: `Object[]` 数组 + 双指针

再来看看 `Map` 接口下面的集合。

#### Map

- `HashMap`： JDK1.8 之前 `HashMap` 由数组+链表组成的，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间
- `LinkedHashMap`： `LinkedHashMap` 继承自 `HashMap`，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，`LinkedHashMap` 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：[《LinkedHashMap 源码详细分析（JDK1.8）》open in new window](https://www.imooc.com/article/22931)
- `Hashtable`： 数组+链表组成的，数组是 `Hashtable` 的主体，链表则是主要为了解决哈希冲突而存在的
- `TreeMap`： 红黑树（自平衡的排序二叉树）



### 哪些集合类是线程安全的？

- Vector：相当于有同步机制的ArrayList 
- Stack：栈 
- HashTable 
- enumeration：枚举



##  Collection 子接口之 List

---

### Array 和 ArrayList 有什么区别？ 

- Array可以包含基本类型和对象类型，ArrayList只能包含对象类型。 
- Array大小是固定的，ArrayList的大小是动态变化的。(ArrayList的扩容是个常见面试题) 
- 相比于Array，ArrayList有着更多的内置方法，如addAll()，removeAll()。 
- 对于基本类型数据，ArrayList 使用自动装箱来减少编码工作量；而当处理固定大小的基本数据类型的时候，这种方式相对比较慢，这时候应该使用Array。



### ArrayList和Vector的区别是什么？ 

- **相同点** 
  1. 都实现了List接口 
  2. 底层数据结构都是数组 

- **不同点** 

  1. 线程安全：Vector使用了Synchronized来实现线程同步，所以是线程安全的，而ArrayList是线程不安全的。 

  2. 性能：由于Vector使用了Synchronized进行加锁，所以性能不如ArrayList。 
  3. 扩容：ArrayList和Vector都会根据需要动态的调整容量，但是ArrayList每次扩容为旧容量的1.5倍，而Vector每次扩容为旧容量的2倍。



### ArrayList 与 LinkedList 区别?

- **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
- **底层数据结构：** `ArrayList` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
- 插入和删除是否受元素位置的影响：
  - `ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
  - `LinkedList` 采用链表存储，所以，如果是在头尾插入或者删除元素不受元素位置的影响（`add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()` 、 `removeLast()`），时间复杂度为 O(1)，如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入。
- **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。
- **内存空间占用：** `ArrayList` 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。



### 迭代器Iterator是什么　 

Iterator 是 Java 迭代器最简单的实现，它不是一个集合，它是一种用于访问集合的方法，Iterator接口提供遍历任何Collection的接口。



### Collection和Collections有什么区别？ 

- Collection 是一个`集合接口`。它提供了对集合对象进行基本操作的通用接口方法。 
- Collections 是一个包装类。它包含有各种有关集合操作的`静态多态方法`，例如常用的sort()方法。此类`不能实例化`，就像一个工具类，服务于Java的Collection框架。



### comparable 和 comparator的区别？　 

- comparable接口出自java.lang包，可以理解为一个内比较器，因为实现了Comparable接口的类可以和自己比较，要和其他实现了Comparable接口类比较，可以使用compareTo(Object obj)方法。compareTo方法的返回值是int，有三种情况： 
  1. 返回正整数（比较者大于被比较者） 
  2. 返回0（比较者等于被比较者） 
  3. 返回负整数（比较者小于被比较者） 

- comparator接口出自java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序，返回值同样是int，有三种情况，和compareTo类似。 

它们之间的区别：很多包装类都实现了comparable接口，像Integer、String等，所以直接调用Collections.sort()直接可以使用。如果对类里面自带的自然排序不满意，而又不能修改其源代码的情况下，使用Comparator就比较合适。此外使用Comparator可以避免添加额外的代码与我们的目标类耦合，同时可以定义多种排序规则，这一点是Comparable接口没法做到的，从灵活性和扩展性讲Comparator更优，故在面对自定义排序的需求时，可以优先考虑使用Comparator接口。



### 遍历一个List有哪些不同的方式？ 

先说一下常见的元素在内存中的存储方式，主要有两种： 

1. 顺序存储（Random Access）：相邻的数据元素在内存中的位置也是相邻的，可以根据元素的位置（如ArrayList中的下表）读取元素。 
2. 链式存储（Sequential Access）：每个数据元素包含它下一个元素的内存地址，在内存中不要求相邻。例如LinkedList。 

主要的遍历方式主要有三种： 

1. `for循环遍历`：遍历者自己在集合外部维护一个计数器，依次读取每一个位置的元素。 
2. `Iterator遍历`：基于顺序存储集合的Iterator可以直接按位置访问数据。基于链式存储集合的Iterator，需要保存当前遍历的位置，然后根据当前位置来向前或者向后移动指针。 
3. `foreach遍历`：foreach 内部也是采用了Iterator的方式实现，但使用时不需要显示地声明Iterator。 

那么对于以上三种遍历方式应该如何选取呢？ 

在Java集合框架中，提供了一个RandomAccess接口，该接口没有方法，只是一个标记。通常用来标记List的实现是否支持RandomAccess。所以在遍历时，可以先判断是否支持RandomAccess（list instanceof RandomAccess），如果支持可用 for循环遍历，否则建议用Iterator或 foreach遍历。



### Java集合的快速失败机制 “fail-fast”和安全失败机制“fail-safe”是什么？

#### 快速失败

Java的快速失败机制是Java集合框架中的一种错误检测机制，当多个线程同时对集合中的内容进行修改时可能就会抛出ConcurrentModificationException异常。其实不仅仅是在多线程状态下，在单线程中用增强for循环中一边遍历集合一边修改集合的元素也会抛出ConcurrentModificationException异常。看下面代码

```java
public class Main{ 
    public static void main(String[] args) { 
        List list = new ArrayList<>(); 
        for(Integer i : list){ 
            list.remove(i); //运行时抛出ConcurrentModificationException异常 
        } 
    } 
}
```

正确的做法是用迭代器的remove()方法，便可正常运行。

```java
public class Main{ 
    public static void main(String[] args) { 
    List list = new ArrayList<>(); 
    Iterator it = list.iterator(); 
    while(it.hasNext()){ 
        it.remove(); 
     } 
  } 
}
```

```java
final void checkForComodification() { 
    if (modCount != expectedModCount) 
        throw new ConcurrentModificationException(); 
}
```

从上面代码中可以看到如果modCount和expectedModCount这两个变量不相等就会抛出ConcurrentModificationException异常。那这两个变量又是什么呢？继续看源码

```java
protected transient int modCount = 0; //在AbstractList中定义的变量
```

```java
int expectedModCount = modCount;//在ArrayList中的内部类Itr中定义的变量
```

从上面代码可以看到，modCount初始值为0，而expectedModCount初始值等于modCount。也就是说在遍历的时候直接调用集合的remove()方法会导致modCount不等于expectedModCount进而抛出ConcurrentModificationException异常，而使用迭代器的remove()方法则不会出现这种问题。那么只能在看看remove()方法的源码找找原因了

```java
public E remove(int index) { 
    rangeCheck(index); modCount++; 
    E oldValue = elementData(index); 
    int numMoved = size - index - 1; 
    if (numMoved > 0) 
        System.arraycopy(elementData, index+1, elementData, index, numMoved); 
    elementData[--size] = null; // clear to let GC do its work 
    return oldValue; 
}
```

从上面代码中可以看到只有modCount++了，而expectedModCount没有操作，当每一次迭代时，迭代器会比较expectedModCount和modCount的值是否相等，所以在调用remove()方法后，modCount不等于expectedModCount了，这时就了报ConcurrentModificationException异常。但用迭代器中remove()的方法为什么不抛异常呢？原来迭代器调用的remove()方法和上面的remove()方法不是同一个！迭代器调用的remove()方法长这样：

```java
public void remove() { 
    if (lastRet < 0) throw new IllegalStateException(); 
    checkForComodification(); 
    try { 
        ArrayList.this.remove(lastRet); 
        cursor = lastRet; lastRet = -1; 
        expectedModCount = modCount; //这行代码保证了expectedModCount和modCount是相等的 
    } catch (IndexOutOfBoundsException ex) { 
        throw new ConcurrentModificationException(); 
    } 
}
```

从上面代码可以看到expectedModCount = modCount，所以迭代器的remove()方法保证了expectedModCount和modCount是相等的，进而保证了在增强for循环中修改集合内容不会报ConcurrentModificationException异常。 

上面介绍的只是单线程的情况，用迭代器调用remove()方法即可正常运行，但如果是多线程会怎么样呢？ 

答案是在多线程的情况下即使用了迭代器调用remove()方法，还是会报ConcurrentModificationException异常。这又是为什么呢？还是要从expectedModCount和modCount这两个变量入手分析，刚刚说了modCount在AbstractList类中定义，而expectedModCount在ArrayList内部类中定义，所以modCount是个共享变量而expectedModCount是属于线程各自的。简单说，线程1更新了modCount和属于自己的expectedModCount，而在线程2看来只有modCount更新了，expectedModCount并未更新，所以会抛出ConcurrentModificationException异常。



#### 安全失败 

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会抛出ConcurrentModificationException异常。缺点是迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生了修改，迭代器是无法访问到修改后的内容。java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用。



### ArrayList自动扩容？

每当向数组中添加元素时，都要去检查添加后元素的个数是否会超出当前数组的长度，如果超出，数组将会进行扩容，以满足添加数据的需求。数组扩容通过ensureCapacity(int minCapacity)方法来实现。在实际添加大量元素前，我也可以使用ensureCapacity来手动增加ArrayList实例的容量，以减少递增式再分配的数量。

数组进行扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量的增长大约是其原容量的1.5倍。这种操作的代价是很高的，因此在实际使用时，我们应该尽量避免数组容量的扩张。当我们可预知要保存的元素的多少时，要在构造ArrayList实例时，就指定其容量，以避免数组扩容的发生。或者根据实际需求，通过调用ensureCapacity方法来手动增加ArrayList实例的容量。

![ArrayList_add](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/863eb5a6-c78b-4879-8bfd-ed871065b171_ArrayList_add.png)



### 简述ArrayList、Vector、LinkedList 的存储性能和特性？

- ArrayList底层数据结构为数组，对元素的读取速度快，而增删数据慢，线程不安全。 
- LinkedList底层为双向链表，对元素的增删数据快，读取慢，线程不安全。 
- Vector的底层数据结构为数组，用Synchronized来保证线程安全，性能较差，但线程安全。



###  comparable 和 Comparator 的区别

- `comparable` 接口实际上是出自`java.lang`包 它有一个 `compareTo(Object obj)`方法用来排序
- `comparator`接口实际上是出自 java.util 包它有一个`compare(Object obj1, Object obj2)`方法用来排序

一般我们需要对一个集合使用自定义排序时，我们就要重写`compareTo()`方法或`compare()`方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写`compareTo()`方法和使用自制的`Comparator`方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 `Collections.sort()`.

#### [#](#comparator-定制排序) Comparator 定制排序



```java
        ArrayList<Integer> arrayList = new ArrayList<Integer>();
        arrayList.add(-1);
        arrayList.add(3);
        arrayList.add(3);
        arrayList.add(-5);
        arrayList.add(7);
        arrayList.add(4);
        arrayList.add(-9);
        arrayList.add(-7);
        System.out.println("原始数组:");
        System.out.println(arrayList);
        // void reverse(List list)：反转
        Collections.reverse(arrayList);
        System.out.println("Collections.reverse(arrayList):");
        System.out.println(arrayList);

        // void sort(List list),按自然排序的升序排序
        Collections.sort(arrayList);
        System.out.println("Collections.sort(arrayList):");
        System.out.println(arrayList);
        // 定制排序的用法
        Collections.sort(arrayList, new Comparator<Integer>() {

            @Override
            public int compare(Integer o1, Integer o2) {
                return o2.compareTo(o1);
            }
        });
        System.out.println("定制排序后：");
        System.out.println(arrayList);
```

Output:



```text
原始数组:
[-1, 3, 3, -5, 7, 4, -9, -7]
Collections.reverse(arrayList):
[-7, -9, 4, 7, -5, 3, 3, -1]
Collections.sort(arrayList):
[-9, -7, -5, -1, 3, 3, 4, 7]
定制排序后：
[7, 4, 3, 3, -1, -5, -7, -9]
```

#### [#](#重写-compareto-方法实现按年龄来排序) 重写 compareTo 方法实现按年龄来排序



```java
// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列
// 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他
// 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了
public  class Person implements Comparable<Person> {
    private String name;
    private int age;

    public Person(String name, int age) {
        super();
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    /**
     * T重写compareTo方法实现按年龄来排序
     */
    @Override
    public int compareTo(Person o) {
        if (this.age > o.getAge()) {
            return 1;
        }
        if (this.age < o.getAge()) {
            return -1;
        }
        return 0;
    }
}
```



```java
    public static void main(String[] args) {
        TreeMap<Person, String> pdata = new TreeMap<Person, String>();
        pdata.put(new Person("张三", 30), "zhangsan");
        pdata.put(new Person("李四", 20), "lisi");
        pdata.put(new Person("王五", 10), "wangwu");
        pdata.put(new Person("小红", 5), "xiaohong");
        // 得到key的值的同时得到key所对应的值
        Set<Person> keys = pdata.keySet();
        for (Person key : keys) {
            System.out.println(key.getAge() + "-" + key.getName());

        }
    }
```

Output：

```text
5-小红
10-王五
20-李四
30-张三
```



## Collection 子接口之 Set

---

### 说一下HashSet的实现原理 

HashSet的底层是HashMap，默认构造函数是构建一个初始容量为16，负载因子为0.75 的HashMap。HashSet的值存放于HashMap的key上，HashMap的value统一为PRESENT。

### HashSet如何检查重复？（HashSet是如何保证数据不可重复的？)

HashSet的特点是存储元素时无序且唯一，在向HashSet中添加对象时，首相会计算对象的HashCode值来确定对象的存储位置，如果该位置没有其他对象，直接将该对象添加到该位置；如果该存储位置有存储其他对象（新添加的对象和该存储位置的对象的HashCode值相同），调用equals方法判断两个对象是否相同，如果相同，则添加对象失败，如果不相同，则会将该对象重新散列到其他位置。



## Collection 子接口之 Queue

---

### Queue 与 Deque 的区别

`Queue` 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 **先进先出（FIFO）** 规则。

`Queue` 扩展了 `Collection` 的接口，根据 **因为容量问题而导致操作失败后处理方式的不同** 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。

| `Queue` 接口 | 抛出异常  | 返回特殊值 |
| ------------ | --------- | ---------- |
| 插入队尾     | add(E e)  | offer(E e) |
| 删除队首     | remove()  | poll()     |
| 查询队首元素 | element() | peek()     |

`Deque` 是双端队列，在队列的两端均可以插入或删除元素。

`Deque` 扩展了 `Queue` 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：

| `Deque` 接口 | 抛出异常      | 返回特殊值      |
| ------------ | ------------- | --------------- |
| 插入队首     | addFirst(E e) | offerFirst(E e) |
| 插入队尾     | addLast(E e)  | offerLast(E e)  |
| 删除队首     | removeFirst() | pollFirst()     |
| 删除队尾     | removeLast()  | pollLast()      |
| 查询队首元素 | getFirst()    | peekFirst()     |
| 查询队尾元素 | getLast()     | peekLast()      |

事实上，`Deque` 还提供有 `push()` 和 `pop()` 等其他方法，可用于模拟栈。

### ArrayDeque 与 LinkedList 的区别

`ArrayDeque` 和 `LinkedList` 都实现了 `Deque` 接口，两者都具有队列的功能，但两者有什么区别呢？

- `ArrayDeque` 是基于可变长的数组和双指针来实现，而 `LinkedList` 则通过链表来实现。
- `ArrayDeque` 不支持存储 `NULL` 数据，但 `LinkedList` 支持。
- `ArrayDeque` 是在 JDK1.6 才被引入的，而`LinkedList` 早在 JDK1.2 时就已经存在。
- `ArrayDeque` 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 `LinkedList` 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。

从性能的角度上，选用 `ArrayDeque` 来实现队列要比 `LinkedList` 更好。此外，`ArrayDeque` 也可以用于实现栈。

### 说一说 PriorityQueue

`PriorityQueue` 是在 JDK1.5 中被引入的, 其与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

这里列举其相关的一些要点：

- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。

`PriorityQueue` 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第K大的数、带权图的遍历等，所以需要会熟练使用才行。



##  Map 接口

---

### HashSet与HashMap的区别

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/ad757c56-9336-458b-8a06-d57287b49376_HashSet和Map对比.png)



### HashMap 和 Hashtable 的区别

- **线程是否安全：** `HashMap` 是非线程安全的，`Hashtable` 是线程安全的,因为 `Hashtable` 内部的方法基本都经过`synchronized` 修饰。（如果你要保证线程安全的话就使用 `ConcurrentHashMap` 吧！）；
- **效率：** 因为线程安全的问题，`HashMap` 要比 `Hashtable` 效率高一点。另外，`Hashtable` 基本被淘汰，不要在代码中使用它；
- **对 Null key 和 Null value 的支持：** `HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 `NullPointerException`。
- **初始容量大小和每次扩充容量大小的不同 ：** ① 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。`HashMap` 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 `Hashtable` 会直接使用你给定的大小，而 `HashMap` 会将其扩充为 2 的幂次方大小（`HashMap` 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 `HashMap` 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。
- **底层数据结构：** JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。`Hashtable` 没有这样的机制。



### HashTable的底层实现知道吗？ 

HashTable的底层数据结构是数组+链表，链表主要是为了解决哈希冲突，并且整个数组都是synchronized修饰的，所以HashTable是线程安全的，但锁的粒度太大，锁的竞争非常激烈，效率很低。

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/a51851cc-fd60-4b42-88ee-1eb9f9070168_hashtable.jpg)



###  HashMap 和 TreeMap 区别

`TreeMap` 和`HashMap` 都继承自`AbstractMap` ，但是需要注意的是`TreeMap`它还实现了`NavigableMap`接口和`SortedMap` 接口。

![TreeMap 继承关系图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/treemap_hierarchy.png)

实现 `NavigableMap` 接口让 `TreeMap` 有了对集合内元素的搜索的能力。

实现`SortedMap`接口让 `TreeMap` 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。示例代码如下：

```java
/**
 * @author shuang.kou
 * @createTime 2020年06月15日 17:02:00
 */
public class Person {
    private Integer age;

    public Person(Integer age) {
        this.age = age;
    }

    public Integer getAge() {
        return age;
    }


    public static void main(String[] args) {
        TreeMap<Person, String> treeMap = new TreeMap<>(new Comparator<Person>() {
            @Override
            public int compare(Person person1, Person person2) {
                int num = person1.getAge() - person2.getAge();
                return Integer.compare(num, 0);
            }
        });
        treeMap.put(new Person(3), "person1");
        treeMap.put(new Person(18), "person2");
        treeMap.put(new Person(35), "person3");
        treeMap.put(new Person(16), "person4");
        treeMap.entrySet().stream().forEach(personStringEntry -> {
            System.out.println(personStringEntry.getValue());
        });
    }
}
```

输出:

```text
person1
person4
person2
person3
```

可以看出，`TreeMap` 中的元素已经是按照 `Person` 的 age 字段的升序来排列了。

上面，我们是通过传入匿名内部类的方式实现的，你可以将代码替换成 Lambda 表达式实现的方式：

```java
TreeMap<Person, String> treeMap = new TreeMap<>((person1, person2) -> {
  int num = person1.getAge() - person2.getAge();
  return Integer.compare(num, 0);
});
```

**综上，相比于`HashMap`来说 `TreeMap` 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力**



###  HashMap 的底层实现

#### JDK1.8 之前

JDK1.8 之前 `HashMap` 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**。HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

所谓扰动函数指的就是 HashMap 的 `hash` 方法。使用 `hash` 方法也就是扰动函数是为了防止一些实现比较差的 `hashCode()` 方法 换句话说使用扰动函数之后可以减少碰撞。

**JDK 1.8 HashMap 的 hash 方法源码:**

JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。

```java
    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
```

对比一下 JDK1.7 的 HashMap 的 hash 方法源码.

```java
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).

    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}
```

相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。

> JDK1.8的函数经过了一次异或一次位运算一共两次扰动，而JDK1.7经过了四次位运算五次异或一共九次扰动。这里简单解释下JDK1.8的hash函数，面试经常问这个，两次扰动分别是key.hashCode()与key.hashCode()右移16位进行异或。这样做的目的是，高16位不变，低16位与高16位进行异或操作，进而减少碰撞的发生，高低Bit都参与到Hash的计算。如何不进行扰动处理，因为hash值有32位，直接对数组的长度求余，起作用只是hash值的几个低位。

所谓 **“拉链法”** 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

![jdk1.8 之前的内部结构-HashMap](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/jdk1.7_hashmap.png)

#### JDK1.8 之后

相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

![jdk1.8之后的内部结构-HashMap](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/jdk1.8_hashmap.png)

> TreeMap、TreeSet 以及 JDK1.8 之后的 HashMap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。

我们来结合源码分析一下 `HashMap` 链表到红黑树的转换。

**1、 `putVal` 方法中执行链表转红黑树的判断逻辑。**

链表的长度大于 8 的时候，就执行 `treeifyBin` （转换红黑树）的逻辑。

```java
// 遍历链表
for (int binCount = 0; ; ++binCount) {
    // 遍历到链表最后一个节点
    if ((e = p.next) == null) {
        p.next = newNode(hash, key, value, null);
        // 如果链表元素个数大于等于TREEIFY_THRESHOLD（8）
        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
            // 红黑树转换（并不会直接转换成红黑树）
            treeifyBin(tab, hash);
        break;
    }
    if (e.hash == hash &&
        ((k = e.key) == key || (key != null && key.equals(k))))
        break;
    p = e;
}
```

**2、`treeifyBin` 方法中判断是否真的转换为红黑树。**

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    // 判断当前数组的长度是否小于 64
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        // 如果当前数组的长度小于 64，那么会选择先进行数组扩容
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        // 否则才将列表转换为红黑树

        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树



### HashMap 的长度为什么是 2 的幂次方

为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。

这道题我想了几天，之前和群里小伙伴们探讨每日一题的时候，问他们为什么 length%hash == (n - 1) & hash，它们说相等的前提是 length 的长度 2 的幂次方，然后我回了一句难道 length 还能不是 2 的幂次方吗？其实是我没有搞懂因果关系，因为 HashMap 的长度是 2 的幂次方，所以使用余数来判断在桶中的下标。如果 length 的长度不是 2 的幂次方，小伙伴们可以举个例子来试试

> 例如长度为 9 时候，3 & (9-1) = 0，2 & (9-1) = 0 ，都在 0 上，碰撞了；

这样会增大 HashMap 碰撞的几率。



### HashMap 多线程操作导致死循环问题

HashMap 不是一个线程安全的容器，在高并发场景下，应该使用 `ConcurrentHashMap`，在多线程场景下使用 HashMap 会造成死循环问题（基于 JDK1.7），出现问题的位置在 `rehash` 处，也就是

```java
do {
    Entry<K,V> next = e.next; // <--假设线程一执行到这里就被调度挂起了
    int i = indexFor(e.hash, newCapacity);
    e.next = newTable[i];
    newTable[i] = e;
    e = next;
} while (e != null);
```

这是 JDK1.7 的 rehash 代码片段，在并发的场景下会形成环。

JDK1.8 也会造成死循环问题。



### HashMap 线程安全的实现有哪些

因为 HashMap 不是一个线程安全的容器，所以并发场景下推荐使用 `ConcurrentHashMap`，或者使用线程安全的 HashMap，使用 `Collections` 包下的线程安全的容器，比如说

```java
Collections.synchronizedMap(new HashMap());
```

还可以使用 HashTable ，它也是线程安全的容器，基于 key-value 存储，经常用 HashMap 和 HashTable 做比较就是因为 HashTable 的数据结构和 HashMap 相同。

上面效率最高的就是 ConcurrentHashMap。



### 讲一下 HashMap put 的过程

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/a2ff1be2-2fa5-45ed-83a9-c7201d5d050e_hashmap的put方法.jpg)

首先会使用 hash 函数来计算 key，然后执行真正的插入方法

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
  Node<K,V>[] tab; Node<K,V> p; int n, i;
  // 如果table 为null 或者没有为table分配内存，就resize一次
  if ((tab = table) == null || (n = tab.length) == 0)
    n = (tab = resize()).length;
  // 指定hash值节点为空则直接插入，这个(n - 1) & hash才是表中真正的哈希
  if ((p = tab[i = (n - 1) & hash]) == null)
    tab[i] = newNode(hash, key, value, null);
  // 如果不为空
  else {
    Node<K,V> e; K k;
    // 计算表中的这个真正的哈希值与要插入的key.hash相比
    if (p.hash == hash &&
        ((k = p.key) == key || (key != null && key.equals(k))))
      e = p;
    // 若不同的话，并且当前节点已经在 TreeNode 上了
    else if (p instanceof TreeNode)
      // 采用红黑树存储方式
      e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
    // key.hash 不同并且也不再 TreeNode 上，在链表上找到 p.next==null
    else {
      for (int binCount = 0; ; ++binCount) {
        if ((e = p.next) == null) {
          // 在表尾插入
          p.next = newNode(hash, key, value, null);
          // 新增节点后如果节点个数到达阈值，则进入 treeifyBin() 进行再次判断
          if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
            treeifyBin(tab, hash);
          break;
        }
        // 如果找到了同hash、key的节点，那么直接退出循环
        if (e.hash == hash &&
            ((k = e.key) == key || (key != null && key.equals(k))))
          break;
        // 更新 p 指向下一节点
        p = e;
      }
    }
    // map中含有旧值，返回旧值
    if (e != null) { // existing mapping for key
      V oldValue = e.value;
      if (!onlyIfAbsent || oldValue == null)
        e.value = value;
      afterNodeAccess(e);
      return oldValue;
    }
  }
  // map调整次数 + 1
  ++modCount;
  // 键值对的数量达到阈值，需要扩容
  if (++size > threshold)
    resize();
  afterNodeInsertion(evict);
  return null;
}
```

HashMap put 方法的核心就是在 `putval` 方法，它的插入过程如下

- 首先会判断 HashMap 中是否是新构建的，如果是的话会首先进行 resize
- 然后判断需要插入的元素在 HashMap 中是否已经存在（说明出现了碰撞情况），如果不存在，直接生成新的k-v 节点存放，再判断是否需要扩容。
- 如果要插入的元素已经存在的话，说明发生了冲突，这就会转换成链表或者红黑树来解决冲突，首先判断链表中的 hash，key 是否相等，如果相等的话，就用新值替换旧值，如果节点是属于 TreeNode 类型，会直接在红黑树中进行处理，如果 hash ,key 不相等也不属于 TreeNode 类型，会直接转换为链表处理，进行链表遍历，如果链表的 next 节点是 null，判断是否转换为红黑树，如果不转换的话，在遍历过程中找到 key 完全相等的节点，则用新节点替换老节点



### HashMap的扩容操作是怎么实现的？

- 初始值为16，负载因子为0.75，阈值为负载因子*容量 
- resize()方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize()方法进行扩容。 
- 每次扩容，容量都是之前的两倍 扩容时有个判断e.hash & oldCap是否为零，也就是相当于hash值对数组长度的取余操作，若等于0，则位置不变，若等于1，位置变为原位置加旧容量。



### HashMap默认加载因子为什么选择0.75？

这个主要是考虑空间利用率和查询成本的一个折中。如果加载因子过高，空间利用率提高，但是会使得哈希冲突的概率增加；如果加载因子过低，会频繁扩容，哈希冲突概率降低，但是会使得空间利用率变低。具体为什么是0.75，不是0.74或0.76，这是一个基于数学分析（泊松分布）和行业规定一起得到的一个结论。



### 为什么要将HashMap链表中转红黑树的阈值设为8？为什么不一开始直接使用红黑树？

可能有很多人会问，既然红黑树性能这么好，为什么不一开始直接使用红黑树，而是先用链表，链表长度大于8时，才转换为红红黑树。 

- 因为红黑树的节点所占的空间是普通链表节点的两倍，但查找的时间复杂度低，所以只有当节点特别多时，红黑树的优点才能体现出来。至于为什么是8，是通过数据分析统计出来的一个结果，链表长度到达8的概率是很低的，综合链表和红黑树的性能优缺点考虑将大于8的链表转化为红黑树。 
- 链表转化为红黑树除了链表长度大于8，还要HashMap中的数组长度大于64。也就是如果HashMap长度小于64，链表长度大于8是不会转化为红黑树的，而是直接扩容。



### HashMap是怎么解决哈希冲突的？ 

哈希冲突：hashMap在存储元素时会先计算key的hash值来确定存储位置，因为key的hash值计算最后有个对数组长度取余的操作，所以即使不同的key也可能计算出相同的hash值，这样就引起了hash冲突。hashMap的底层结构中的链表/红黑树就是用来解决这个问题的。 HashMap中的哈希冲突解决方式可以主要从三方面考虑（以JDK1.8为背景） 

- 拉链法HasMap中的数据结构为数组+链表/红黑树，当不同的key计算出的hash值相同时，就用链表的形式将Node结点（冲突的key及key对应的value）挂在数组后面。 
- hash函数key的hash值经过两次扰动，key的hashCode值与key的hashCode值的右移16位进行异或，然后对数组的长度取余（实际为了提高性能用的是位运算，但目的和取余一样），这样做可以让hashCode取值出的高位也参与运算，进一步降低hash冲突的概率，使得数据分布更平均。 
- 红黑树在拉链法中，如果hash冲突特别严重，则会导致数组上挂的链表长度过长，性能变差，因此在链表长度大于8时，将链表转化为红黑树，可以提高遍历链表的速度。



### HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？ 

hashCode()处理后的哈希值范围太大，不可能在内存建立这么大的数组。



### ConcurrentHashMap底层具体实现知道吗？

**JDK1.7** 

在JDK1.7中，ConcurrentHashMap采用Segment数组 + HashEntry数组的方式进行实现。Segment实现了ReentrantLock，所以Segment有锁的性质，HashEntry用于存储键值对。一个ConcurrentHashMap包含着一个Segment数组，一个Segment包含着一个HashEntry数组，HashEntry是一个链表结构，如果要获取HashEntry中的元素，要先获得Segment的锁。

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/552eb8a4-cf98-45aa-8432-c3e897302b58_ConcurrentHashMap1.jpg)

JDK1.8 

在JDK1.8中，不在是Segment+HashEntry的结构了，而是和HashMap类似的结构，Node数组+链表/红黑树，采用CAS+synchronized来保证线程安全。当链表长度大于8，链表转化为红黑树。在JDK1.8中synchronized只锁链表或红黑树的头节点，是一种相比于segment更为细粒度的锁，锁的竞争变小，所以效率更高。

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/8bcb3c13-8328-4860-82e2-044784a981ef_ConcurrentHashMap2.jpg)

总结一下： 

- JDK1.7底层是ReentrantLock+Segment+HashEntry，JDK1.8底层是synchronized+CAS+链表/红黑树 
- JDK1.7采用的是分段锁，同时锁住几个HashEntry，JDK1.8锁的是Node节点，只要没有发生哈希冲突，就不会产生锁的竞争。所以JDK1.8相比于JDK1.7提供了一种粒度更小的锁，减少了锁的竞争，提高了ConcurrentHashMap的并发能力。



### JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？

- **线程安全实现方式** ：JDK 1.7 采用 `Segment` 分段锁来保证安全， `Segment` 是继承自 `ReentrantLock`。JDK1.8 放弃了 `Segment` 分段锁的设计，采用 `Node + CAS + synchronized` 保证线程安全，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点。
- **Hash 碰撞解决方法** : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。
- **并发度** ：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。



### HashMap、ConcurrentHashMap及Hashtable的区别

![](https://vue-admin-imgages.oss-cn-hangzhou.aliyuncs.com/2022-11-27/284f5e04-4d05-4ef7-8334-68c3973510b0_hash.png)